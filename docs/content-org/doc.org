#+STARTUP: content
#+AUTHOR: Iris Garcia
#+HUGO_BASE_DIR: ../
#+HUGO_AUTO_SET_LASTMOD: t
#+OPTIONS: toc:nil

* Homepage
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :nocomment true :nodate true :nopaging true :noread true :chapter true
:EXPORT_HUGO_SECTION:
:EXPORT_HUGO_BUNDLE: /
:EXPORT_HUGO_WEIGHT: 1
:EXPORT_FILE_NAME: _index
:END:
<h1>Workday</h1>
[[/images/workday.png]]

{{% notice note %}}
This site hosts the documentation of Workday.
{{% /notice %}}

* Sections
** Description
:PROPERTIES:
:EXPORT_HUGO_SECTION: description
:EXPORT_HUGO_WEIGHT: 1
:END:
*** Description
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :chapter true :pre "<b>1. </b>"
:END:
<h3> Chapter 1 </h3>
<h1>Description</h1>

Get a general idea of what is Workday and the motivation to start its
development.

*** What is Workday?
:PROPERTIES:
:EXPORT_FILE_NAME: description/what
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:END:
Workday is a RESTful API project that allows the management of
workers' day registration, for this purpose it makes use of a
relational database where such data persists.

It allows the creation of different types of users (roles), initially
there are two main roles:
1. ~employee~: The employee has permissions to:
   - Register checks in and checks out.
   - Update their own password.
   - Update their own schedule.
2. ~HR~: The Human Resources role is the one with almost full control,
   it has the permissions of a regular employee plus:
   - Retrieve every employee's schedule.
   - Register employees.
   - Remove employees.
   - Reset employees' password.

The final goal is to build clients consuming this API to improve the
user experience, for example:

An Android/iOS app which automatically registers the checks in when the
GPS location is near the Office's location and the checks out when it
gets away from the Office's location.

*** Why?
:PROPERTIES:
:EXPORT_FILE_NAME: description/why
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:END:
Since last May 12, 2019 every Spanish company is required to provide
their employees a process to record their working hours.

This process can be as simple as signing in a paper the checks in and
checks out for every single workday; but any other process can be used
and this is the reason for which I decided to develop this project.

** Development
:PROPERTIES:
:EXPORT_HUGO_SECTION: dev
:EXPORT_HUGO_WEIGHT: 2
:END:
*** Development
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :chapter true :pre "<b>2. </b>"
:END:
<h3> Chapter 2 </h3>
<h1>Development</h1>

This chapter shows which tools are used in the development of the
project and how to set up a working dev environment.

*** Requirements
:PROPERTIES:
:EXPORT_FILE_NAME: dev/requirements
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:EXPORT_HUGO_WEIGHT: 2
:END:
**** Go
- *Version used*: 1.13.1
- *Setup*: Most of the linux distributions provide a package to
  install Go, but it is also possible to download its binary.
  #+begin_src bash
  wget https://dl.google.com/go/go1.13.3.src.tar.gz
  tar -C /usr/local -xzf go1.13.3.src.tar.gz
  export PATH=$PATH:/usr/local/go/bin
  #+end_src
**** Mage
- *Setup*: Once go is installed, we can install mage as follows
  #+begin_src bash
  go get github.com/magefile/mage
  #+end_src
**** MariaDB
- *Version used*: 10.4
- *Setup*: Most of the linux distrubutions provide a package to
  install MariaDB, but if docker is installed the following command
  will spawn a MariaDB container:
  #+begin_src bash
  mage startdev
  #+end_src
**** Nodejs (Production)
- *Version used*: 12.11.1
- Nodejs is only needed to install *PM2* and therefore it is not a
  requirement, however the current state of the project uses it to run
  the service in a production environment.

*** Toolchain
:PROPERTIES:
:EXPORT_FILE_NAME: dev/tools
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:EXPORT_HUGO_WEIGHT: 1
:END:
**** [[https://golang.org/][Go]]
The open source programming language Go will be used to develop the
whole project, mainly because I want to try a new language and this
one is becoming quite popular nowadays.

**** [[https://github.com/gin-gonic/gin][Gin]]
Gin is a HTTP web framework written in Go (Golang). It features a
Martini-like API with much better performance -- up to 40 times
faster.

It is very well documented and provides many handy features like
authentication, data validation and a configurable logger out of the
box.

**** [[https://magefile.org/][Mage]]
Mage is a make/rake-like build tool using Go. You write plain-old go
functions, and Mage automatically uses them as Makefile-like runnable
targets.

Mage has no dependencies outside the Go standard library; in this
project it is going to be used to automate every possible process
like:
1. ~mage test~: runs the test suite.
2. ~mage testverbose~: runs the test suite with verbosity.
3. ~mage testandcoverage~: runs the test suite generating its code coverage.
4. ~mage build~: builds a binary of the project.
5. ~mage install~: installs the built binary under /usr/local/bin.
6. ~mage start~: Starts the HTTP Server using pm2 as process manager.
7. ~mage startdev~: Starts a dev environment, [WIP].
8. ~mage stop~: Stops the HTTP Server using pm2 as process manager.

**** [[https://mariadb.com/][MariaDB]]
The relational database engine MariaDB has been choosen to persist the
data, it is OpenSource and fulfills the requirements.

**** Test-driven development (TDD & BDD)
Go has support for testing built in to its toolchain which will be used to cover
unit and integration tests with the help of [[https://github.com/stretchr/testify][testify]] for the
assertions.

[[https://github.com/onsi/ginkgo][Ginkgo]] will be used as a BDD testing framework and [[https://github.com/onsi/gomega][Gomega]] as a
matcher library.

**** [[https://github.com/OAI/OpenAPI-Specification/][OpenAPI]]
This project will follow the OpenAPI Specification to document its API
endpoints, probably using swagger to parse the specifications and
generate a static site.
**** [[https://pm2.keymetrics.io/][PM2]]
As a process manager the tool *PM2* is currently used, because it
allows the usage with any language as long as it has a way to
build/run it.

Ideally this tool will be replace in favor of a Go tool, some of them
has been already tested but none of them provide the same features as
*PM2*.

*** API Test Class                                               :bdd:test:
:PROPERTIES:
:EXPORT_FILE_NAME: dev/api
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:EXPORT_HUGO_WEIGHT: 3
:END:
**** User story
As an admin employee, I want to be able to:

1. Add new employees to the system.
2. Edit already existing employees' details.
3. List all the employees existing in the system.
4. Retrieve the details of any employee given its ID.
5. Delete an employee from the system given its ID.

**** Endpoints
| Method | Endpoint        |
|--------+-----------------|
| GET    | /status         |
| GET    | /employees      |
| POST   | /employees      |
| GET    | /employees/{id} |
| PUT    | /employees/{id} |
| DELETE | /employees/{id} |

- *GET /status*: Returns a 200 and ~{"status": "OK"}~ in the body.
- *GET /employees*: Returns a 200 and the list of employees stored in the database.
- *POST /employees*: Adds a new employee into the database if the body
  fulfills the requirements (firstname, lastname, role, password),
  otherwise it returns a 204 reponse.
- *GET /employees/{id}*: Returns a 200 and the details of an employee
  if the id is found otherwise a 404.
- *DELETE /employees/{id}*: Returns a 200 and an OK message if the
  employee with *{id}* is found otherwise a 500 and the error.
- *PUT /employees/{id}*: Returns a 200 and an OK message if the
  employee with *{id}* is found, if it is not found a 404 and if any
  other error happens a 500 with the error message.


BDD has been used to test every possible use case to reach a 100%
[[/coverage.html][code coverage]] it is worth to mention that the database has been mocked so
the current tests are *Unit tests*, leaving the *Integration tests*
for a later iteration.

**** Source code
The code which covers the current class can be found [[https://github.com/iris-garcia/workday/blob/master/api/router_test.go][here]].

**** Demo
{{< asciinema key="employees-test" rows="50" preload="1"
idle-time-limit="1" >}}

** Continuous Integration
:PROPERTIES:
:EXPORT_HUGO_SECTION: ci
:EXPORT_HUGO_WEIGHT: 3
:END:
*** Continuous Integration
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :chapter true :pre "<b>3. </b>"
:END:
<h3> Chapter 3 </h3>
<h1>Continuous Integration</h1>

This chapter describes the systems used to continuously integrate
changes into the project.
*** Travis CI                                                          :ci:
:PROPERTIES:
:EXPORT_FILE_NAME: ci/travis
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:EXPORT_HUGO_WEIGHT: 1
:END:
**** Description
Travis is a hosted continuous integration service used to build and
test software projects hosted at GitHub.

It provides a free plan for open source projects which is very
convinient for our use case.

The whole configuration is set up in a single file ~.travis.yml~ which
must be placed in the root directory of the project.
**** Configuration
To avoid replicating exactly the same workflows in GitHub Actions and
Travis, there are some little changes like testing two different Go
versions: ~v1.13.x~ and ~master~ (which is the latest available at any
given time).

It also releases artifacts when a new *tag* is pushed to the
repository.

#+INCLUDE: "../../.travis.yml" src yaml

The following lines tell travis to run the tests against two different
versions of Go (1.13.x and master)

#+begin_src yaml
  go:
  - 1.13.x
  - master
#+end_src

And the following excerpt defines *bionic* as the Ubuntu version to be
used also tells the requirement of *sudo* needed to install ~npm~ and
~pm2~.

#+begin_src yaml
  dist: bionic

  sudo: required

  addons:
    mariadb: '10.1'

  services:
    - mariadb
#+end_src

The *addons* and *services* sections are in place to boot a *mariadb*
service which will be used for the integration tests against a test
database.

The *before_install* and *install* configurations will fetch and setup
all the prerequisites in order to run our *build tool* which is
*mage*.

Finally the *script* will use ~mage~ to start the environment, run the
tests and stop it once it finishes.

*** GitHub Actions                                                     :ci:
:PROPERTIES:
:EXPORT_FILE_NAME: ci/github
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:EXPORT_HUGO_WEIGHT: 2
:END:
**** Description
GitHub Actions is the new continuous integration and deployment system
built and maintained by the community.

**** Configuration
Currently there are two workflows configured:
***** Test with verbosity enabled
To make it a bit different that the pipeline configured in Travis CI,
this one will run the tests with verbosity enabled, this way it
outputs every spec and API call done for each test case.

An example of one run can be seen [[https://github.com/iris-garcia/workday/runs/285177520][here]].
#+INCLUDE: "../../.github/workflows/unittests.yaml" src yaml

There is just one job configured in this *Action* with the name
~checks~ and as stated in the line 8 of the configuration it uses
*Ubuntu* in it latest available version.

There are two steps in this /job/:

The first one Checks out the project repository in its ~master~ branch.

The second one uses an action to automatically setup a Go workspace
and run arbitrary commands, the documentation can be seen [[https://github.com/cedrickring/golang-action][here]].
If no args are specified and a ~Makefile~ is detected, this action will
run ~make~. Otherwise ~go test~ and ~go build~ will be run.

In this case it is overwritten in order to install ~mage~ and ~ginkgo~
CLIs to allow the build and run of the tests.

***** Hugo documentation site
This workflow is not really a typical continuous integration one, but
I think it makes sense to mention it here as it is taking care of
automatically update the documentation site.

#+INCLUDE: "../../.github/workflows/hugo.yml" src yaml

To get this one working there are some requisites explained in a howto
[[/howto/gh-pages][document]].

** Deployment
:PROPERTIES:
:EXPORT_HUGO_SECTION: deployment
:EXPORT_HUGO_WEIGHT: 4
:END:
*** Deployment
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :chapter true :pre "<b>4. </b>"
:END:
<h3> Chapter 4 </h3>
<h1>Deployment</h1>

This chapter describes where and how is this project deployed.
*** OpenShift                                                          :cd:
:PROPERTIES:
:EXPORT_FILE_NAME: deployment/openshit
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:EXPORT_HUGO_WEIGHT: 1
:END:
**** Requirements
***** Create account in RedHat
1. Create a new account using the [[https://developers.redhat.com/auth/realms/rhd/login-actions/registration?client_id=oso&tab_id=ZoheL3ZSJ4g][Sign up]] form.
2. Sign in into [[https://manage.openshift.com/accounts/auth/keycloak][OpenShift]].
***** Install the OpenShift client
#+begin_src bash
  wget https://mirror.openshift.com/pub/openshift-v4/clients/oc/4.1/linux/oc.tar.gz
  tar xvzf oc.tar.gz
  sudo cp oc /usr/local/bin/
#+end_src

{{% notice tip %}}
*The binary can be copied to any place as long as it is included in the $PATH.*
{{% /notice %}}
***** Get the Login command
[[/images/oc_login.png]]
***** Create a Dockerfile
OpenShift can create a docker image given a source git repository, but
it needs a Dockerfile definition which is shown below:
#+CAPTION: Dockerfile
#+INCLUDE: "../../Dockerfile" src dockerfile

The Dockerfile is quite simple and this is expected thanks to the
configuration of the build tool.

**** QuickStart
This is a summary of the needed commands to get the project working:
#+begin_src bash
# Login
oc login --token={REDACTED} --server=https://api.us-east-2.starter.openshift-online.com:6443
# New project
oc new-project workday
# Not needed: mariadb service
oc new-app \
        -e MYSQL_USER=workday \
        -e MYSQL_PASSWORD=workday \
        -e MYSQL_DATABASE=workday \
        mariadb
# Our API service
oc new-app deployment/openshift.yml
# Manually trigger a new build
oc start-build api
#+end_src


{{% notice tip %}}
*For further explanation keep reading the step by step guide.*
{{% /notice %}}

**** Step 1: Login using the CLI
Use the login command from the previous step:
#+begin_src bash
  oc login --token={REDACTED} --server=https://api.us-east-2.starter.openshift-online.com:6443
#+end_src

**** Step 2: Create a new project
#+begin_src bash
  oc new-project workday
#+end_src

**** Step 3: Create a new MariaDB app
#+begin_src bash
  oc new-app \
        -e MYSQL_USER=workday \
        -e MYSQL_PASSWORD=workday \
        -e MYSQL_DATABASE=workday \
        mariadb
#+end_src

{{% notice warning %}}
*This step is not needed yet, but it will be in a near future to get the service fully working.*
{{% /notice %}}

**** Step 4: Create a template for our service
#+CAPTION: openshift.yml
#+INCLUDE: "../../deployment/openshift.yml" src yaml

The template defines 5 main resources to be created in OpenShift:
1. *Service*: exposes connectivity to the API container in a port.
2. *Route*: Creates and endpoint which points to the Service resource.
3. *ImageStream*: Keeps track of of changes in the application image.
4. *BuildConfig*: This resource as it is configured basically fetches
   the source code from the git repository then builds and tags a
   docker image and finally runs the tests to make sure it is a
   working image.
5. *DeploymentConfig*: This resource is the one spawning a new
   container/s with the built image, it has many parameters such as
   the ability to recreate the container automatically when the
   specified image has been changed or the number of replicas, it also
   allows to setup environment variables to the container/s.

**** Step 5: Create a new app using the above template
#+begin_src bash
oc new-app deployment/openshift.yml
#+end_src

**** Step 6: Trigger the build
The build can be triggered manually with the following command:
#+begin_src bash
  oc start-build api
#+end_src

But we don't want to be triggering a new build everytime we integrate
a new change in our service, therefore we have also set up a continuous
delivery process which tests the new changes whenever there is a new
push in the repository and deploys the new version if the tests
passes.

The documentation with a how-to guide can be found [[/howto/openshift/][here]].

**** Demo
{{< asciinema key="openshift" rows="50" preload="1"
idle-time-limit="1" >}}
** How-to
:PROPERTIES:
:EXPORT_HUGO_SECTION: howto
:EXPORT_HUGO_WEIGHT: 5
:END:
*** How-to
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :chapter true :pre "<b>5. </b>"
:END:
<h3> Chapter 5 </h3>
<h1>How to's</h1>

This chapter hosts all the step by step guides which I find useful to
share.

*** GitHub Pages                                              :ci:hugo:doc:
:PROPERTIES:
:EXPORT_HUGO_SECTION: howto/gh-pages
:EXPORT_HUGO_WEIGHT: 1
:END:
**** GitHub Pages
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:END:
This document ilustrates how to setup [[https://pages.github.com/][GitHub Pages]] using [[https://gohugo.io/][Hugo]] as
website generator and [[https://github.com/features/actions][GitHub's Actions]] to automate the deployment
process.

There are different alternatives to setup GitHub pages, the one used
in here is a project pages using ~gh-pages~ branch, the advantages
are:
- It keeps your source and generated website in different branches and
  therefore maintains version control history for both.
- It uses the default Hugo's *public* folder.

So basically this project's repository has the following branches:
- *master*: Hosts the source code of the project under the ~docs/~ folder.
- *gh-pages*: Hosts the static assets generated by hugo.

***** Step 1: Structure
#+begin_src bash
# Docs folder
mkdir docs && cd docs
hugo new site .
git add .
git commit -m "Adds initial hugo site"
git push origin master

# gh-pages branch
git checkout --orphan gh-pages
git reset --hard
git commit --allow-empty -m "Initializing gh-pages branch"
git push origin gh-pages
#+end_src

***** Step 2: Generate a SSH key.
#+begin_src bash
ssh-keygen -t rsa -f hugo -q -N ""
#+end_src

{{% notice note %}}
This will generate the files: ~hugo~ and ~hugo.pub~ which will be
needed for the next steps.
{{% /notice %}}

***** Step 3: Add a deployment key
Navigate to your GitHub's repository settings and under *Deploy keys*
add a new one using the content of the ~hugo.pub~ SSH key generated in
the previous step.

[[/images/deploy_key.png]]

{{% notice warning %}}
Make sure the *Allow write access* is checked, otherwise the GitHub's
Action won't be able to push changes.
{{% /notice %}}

***** Step 4: Create a secret
Navigate to you GitHub's repository settings and under *Secrets* add a
new one using the content of the ~hugo~ SSH private key generated in
the [[Step%202%3A%20Generate%20a%20SSH%20key.][step 2]].

[[/images/gh_secret.png]]

***** Step 5: Add the GitHub's Action.
Create the needed directory in the *hugo* branch:
#+begin_src bash
mkdir -p .github/workflows
#+end_src

Add a new file in the path ~.github/workflows/gh_pages.yml~ with the
following content:
#+INCLUDE: "../../.github/workflows/hugo.yml" src yaml


{{% notice note %}}
Replace the origin's remote with your repository.
{{% /notice %}}

Finally commit and push the changes (which should trigger already the
Action).

#+begin_src bash
git add .github/workflows/gh_pages.yml
git commit -m "Adds GitHub's Action to build hugo site."
git push origin master
#+end_src

***** Step 5: Verify the Action
If everything went well you should already have your site updated and a
new commit to the ~gh-pages~ branch.

You can also see the output of the Action navigating to the *Actions*
section of your repository.

[[/images/gh_action.png]]

*** Continuous Delivery                                  :doc:cd:openshift:
:PROPERTIES:
:EXPORT_HUGO_SECTION: howto/openshift
:EXPORT_HUGO_WEIGHT: 2
:END:
**** Continuous Delivery
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :asciinema true
:END:
Travis offers a deployment configuration which fortunately supports
OpenShift, the following steps shows how to get it working.
***** Prerequisites
****** Travis-CI command line client
The command line client has been used to secure our OpenShift token.
First of all we need to install the CLI following its [[https://github.com/travis-ci/travis.rb#installation][documentation]],
but basically if we already have ~ruby~ installed in our system we
just need to install the following gem:
#+begin_src bash
  gem install travis
#+end_src
****** GitHub and Travis integration
Travis must be integrated in GitHub which can be done in a few steps:
1. Go to https://travis-ci.org/ and sign in with your GitHub account.
2. In the upper right corner click on your name (or choose Accounts)
   to open your Travis-ci profile. You'll be presented with the list
   of your GitHub projects (only the ones where you have
   administrative authority)
3. Toggle the switch on one of your projects and then click on little
   wrench icon to open the project's Integrations & services page on GitHub. To
   get to the same place from your GitHub project, go to Settings >
   Integrations & services.

***** Step 1: Get the OpenShift token
[[/images/oc_login.png]]
Save the token given by the Login command.

***** Step 2: Get the travis API token
In the upper right corner click on your name then Settings and again
the Settings tab as shown in the screenshot, then finally click in
~Copy token~.
[[/images/travis_token.png]]

***** Step 3: Login using the Tavis CLI
#+begin_src bash
  travis login --github-token {{TOKEN}} --com
#+end_src

{{% notice note %}}
Replace ~{{TOKEN}}~ with the real token copied in the step 2.
{{% /notice %}}

***** Step 4: Add and Secure the OpenShift token
First add an environment variable in Travis:
#+begin_src bash
travis env set OPENSHIFT_TOKEN {{TOKEN}} --com
#+end_src
Then add the encrypted value in our ~.travis.yml~ file:
#+begin_src bash
  travis encrypt --add deploy.token {{TOKEN}}
#+end_src

{{% notice note %}}
Replace ~{{TOKEN}}~ with the real token copied in the step 1.
{{% /notice %}}

***** Step 5: Add deploy stage in ~.travis.yml~
The following excerpt shows only the *deploy* stage, the full
configuration file can be found [[https://github.com/iris-garcia/workday/blob/master/.travis.yml][here]].
#+begin_src yaml
  - stage: deploy
      name: Deploy to OpenShift
      script: skip
      deploy:
        provider: openshift
        server: https://api.us-east-2.starter.openshift-online.com:6443
        project: workday
        app: api
        edge: true
        on:
          branch: master
        token:
          secure: dQ/DwmYDyJ2JkhUh++II/1QgnIU/TAlobn//zki+G/Id9+Z4XU0DwGHb+WQuxS+RBqASS79imBkzd0b8uZsSgzf8mEFCEbzikZy3rYGJW/CVFVKygbOBRsM7ms+clAEAr9cet6QqKBeRt6WH3AiPfetcNw0GpjKYr0WGdzzq+sf347NRFrhr/rSiOeugBq2EYqtuXeE6tAzm0ivGLl9C4hDYBdkYiQfJ16hk+/hJrwFRZpVv+7yR9J+WphMVqbCrB0XY3qSnwUlgfMw5QdCFvZAqoZbbiIF0OqEDZ+kwSVSPKPZ/zybpyrE+ty83GGuQ3MymMLM35Upr51HB6VNAcwtpwW8Cf3Bzj2odFKzk26etvUDhaPpXMV8Ow9VgYgweEti9KebdM0esN5emr/7vCmLVe3ppNDhH+tfGGmaVM8dkB+L4d2A4kXoxfHyS59HZPGBVFPLmNrxgwxbVaO7EiqUPlBX7SOMMNKn83HUF96edCOXwqVdznfLaG9Uh1/pvfTj4N1NOO1zTdTuuda4WeXSAyWEpgc15RwNQcYp6smtgXk3zFYKA0ZB9C9jyO01Fvoy96H8llY+wrEVuiUmyzSu3KAk6+86SLPJQUHWsvhSTES7qb6c5oSmoBao7X97b4/3EOGHq86wJLE/6vjrqWlrq3BtXpXqiOcbB5el1a9M=
#+end_src

- The ~server~ parameter must be set accordingly with your OpenShift
  endpoint.
- The ~project~ and ~app~ parameters must match the ones provided in
  the deployment commands.
- The ~edge~ parameter tells Travis to use the deployment version 2
  which is currently in /beta/ (but still recommended by Travis [[https://docs.travis-ci.com/user/deployment/openshift/][here]]).
- The ~script: skip~ parameter tells Travis to don't run any build
  command (we don't have to waste time here).
- Finally the ~on: branch~ parameter tells Travis to only deploy when
  there are changes in the *master* branch.


* Footnotes
[fn:1] Footnote example

* COMMENT Local Variables                                           :ARCHIVE:
# Local Variables:
# eval: (auto-fill-mode 1)
# End
